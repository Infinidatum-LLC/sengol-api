# Server Configuration
NODE_ENV=development
PORT=4000
API_VERSION=v1

# Database
DATABASE_URL=postgresql://user:password@localhost:5432/sengol

# Redis (optional - used for rate limiting if available)
REDIS_URL=redis://localhost:6379

# Authentication
JWT_SECRET=your-super-secret-jwt-key-change-this
JWT_EXPIRES_IN=7d
API_AUTH_TOKEN=your-api-auth-token-for-endpoint-authentication

# OpenAI Configuration
OPENAI_API_KEY=sk-...
OPENAI_TIMEOUT=60000                    # Request timeout in ms (default: 60000)
OPENAI_MAX_RETRIES=3                    # Max retry attempts (default: 3)

# Python Backend
PYTHON_BACKEND_URL=http://localhost:8000

# CORS
ALLOWED_ORIGINS=http://localhost:3000,https://sengol.ai

# Caching Configuration
CACHE_ENABLED=true                      # Enable/disable caching (default: true)
CACHE_TTL=3600                          # Cache TTL in seconds (default: 3600 = 1 hour)
CACHE_MAX_SIZE=1000                     # Max cache size (default: 1000 entries)

# Resilience Configuration
REQUEST_TIMEOUT=120000                  # Global request timeout in ms (default: 120000 = 2 min)
SHUTDOWN_TIMEOUT=30000                  # Graceful shutdown timeout in ms (default: 30000 = 30 sec)

# Monitoring (optional)
SENTRY_DSN=
LOG_LEVEL=info                          # Logging level: trace, debug, info, warn, error, fatal

# Qdrant Vector Database Configuration
QDRANT_HOST=34.44.96.148
QDRANT_PORT=6333
