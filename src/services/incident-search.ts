/**
 * Incident Search Service - Semantic search using Gemini Grounding
 *
 * This service provides evidence-based incident search using Gemini AI grounding
 * which automatically handles embedding generation and semantic ranking.
 *
 * MIGRATION HISTORY:
 * - d-vecDB VPS ‚Üí Google Vertex AI RAG (Nov 2025)
 * - Vertex AI RAG ‚Üí Gemini Grounding (Nov 2025) - eliminates manual embedding management
 *
 * PERFORMANCE OPTIMIZATIONS (Week 2):
 * - L1 Cache: Local memory LRU cache (1-5ms)
 * - L2 Cache: Redis distributed cache (20-50ms)
 * - L3: Gemini grounding with Cloud Storage data (100-3000ms)
 * - Request deduplication (prevents duplicate in-flight requests)
 * - Pre-filtering by metadata (reduces search space by 80-90%)
 */

import { Storage } from '@google-cloud/storage'
import { IncidentMetadata, SearchResult } from '../lib/vertex-ai-client'
import { getGeminiClient } from '../lib/gemini-client'
import {
  vectorSearchCache,
  generateCacheKey,
  getFromLocalCache,
  setInLocalCache,
} from '../lib/local-cache'
import {
  getFromCache,
  setInCache,
  generateVectorSearchKey,
  CACHE_TTL,
} from '../lib/redis-cache'
import { requestDeduplicator } from '../lib/request-deduplicator'
import { getGoogleAuth } from '../lib/google-auth'

// Cloud Storage setup - initialize auth first
getGoogleAuth() // Ensures credentials are properly configured
const storage = new Storage({
  projectId: process.env.GOOGLE_CLOUD_PROJECT?.trim(),
})

const BUCKET_NAME = process.env.GCS_BUCKET_NAME?.trim() || 'sengol-incidents'
const INCIDENT_DATA_PATH = 'incidents/postgres-migrated/raw/'

// Cache for loaded incident data
let incidentCache: Map<string, any[]> | null = null
let cacheTimestamp: number = 0
const CACHE_TTL_MS = 3600000 // 1 hour

export interface IncidentSearchOptions {
  limit?: number
  minSimilarity?: number
  industry?: string
  severity?: string[]
  requireMfaData?: boolean
  requireBackupData?: boolean
  requireIrPlanData?: boolean
  incidentTypes?: string[]
}

export interface IncidentMatch {
  id: string
  incidentId: string
  incidentType: string
  attackType?: string | null
  organization?: string | null
  industry?: string | null
  severity?: string | null
  incidentDate?: Date | null
  hadMfa?: boolean | null
  hadBackups?: boolean | null
  hadIrPlan?: boolean | null
  estimatedCost?: number | null
  downtimeHours?: number | null
  recordsAffected?: number | null
  similarity: number
  embeddingText: string
}

export interface IncidentStatistics {
  totalIncidents: number
  dateRange: { earliest?: Date; latest?: Date }
  avgCost: number
  medianCost: number
  totalCost: number
  incidentsWithCostData: number
  avgDowntime: number
  totalDowntime: number
  incidentsWithDowntimeData: number
  avgRecordsAffected: number
  totalRecordsAffected: number
  incidentsWithRecordsData: number
  mfaAdoptionRate: number
  backupAdoptionRate: number
  irPlanAdoptionRate: number
  incidentsWithSecurityData: number
  costSavingsMfa: number
  costSavingsBackups: number
  costSavingsIrPlan: number
  avgCostWithMfa: number
  avgCostWithoutMfa: number
  avgCostWithBackups: number
  avgCostWithoutBackups: number
  avgCostWithIrPlan: number
  avgCostWithoutIrPlan: number
  severityBreakdown: { low: number; medium: number; high: number; critical: number; unknown: number }
  topIndustries: Array<{ industry: string; count: number }>
}

/**
 * Find similar incidents using d-vecDB vector similarity search
 * WITH 3-TIER CACHING STRATEGY
 */
export async function findSimilarIncidents(
  projectDescription: string,
  options: IncidentSearchOptions = {}
): Promise<IncidentMatch[]> {
  const overallStartTime = Date.now()

  const {
    limit = 20,
    minSimilarity = 0.7,
    industry,
    severity,
    requireMfaData = false,
    requireBackupData = false,
    requireIrPlanData = false,
    incidentTypes,
  } = options

  console.log('\nüîç [SEARCH] Starting incident search with optimizations...')
  console.log(`[SEARCH] Query: "${projectDescription.substring(0, 100)}..."`)
  console.log(`[SEARCH] Filters: limit=${limit}, minSim=${minSimilarity}, industry=${industry || 'all'}`)

  // Generate cache key for this search
  const cacheKey = generateCacheKey({
    query: projectDescription,
    filters: { industry, severity, requireMfaData, requireBackupData, requireIrPlanData, incidentTypes },
    limit,
  })

  const redisCacheKey = generateVectorSearchKey({
    query: projectDescription,
    filters: { industry, severity, incidentTypes },
    limit,
  })

  try {
    // ========================================================================
    // L1 CACHE: Local Memory (1-5ms)
    // ========================================================================
    const l1StartTime = Date.now()
    const l1Cached = getFromLocalCache(vectorSearchCache, 'vectorSearch', cacheKey)

    if (l1Cached) {
      const l1Latency = Date.now() - l1StartTime
      const totalLatency = Date.now() - overallStartTime
      console.log(`[L1 CACHE HIT] ‚úÖ Returned ${l1Cached.length} results in ${l1Latency}ms (total: ${totalLatency}ms)`)
      return l1Cached
    }

    const l1Latency = Date.now() - l1StartTime
    console.log(`[L1 CACHE MISS] Local cache miss (${l1Latency}ms)`)

    // ========================================================================
    // L2 CACHE: Redis (20-50ms)
    // ========================================================================
    const l2StartTime = Date.now()
    const l2Cached = await getFromCache<IncidentMatch[]>(redisCacheKey)

    if (l2Cached) {
      const l2Latency = Date.now() - l2StartTime
      const totalLatency = Date.now() - overallStartTime

      // Populate L1 cache for next time
      setInLocalCache(vectorSearchCache, 'vectorSearch', cacheKey, l2Cached)

      console.log(`[L2 CACHE HIT] ‚úÖ Redis returned ${l2Cached.length} results in ${l2Latency}ms (total: ${totalLatency}ms)`)
      return l2Cached
    }

    const l2Latency = Date.now() - l2StartTime
    console.log(`[L2 CACHE MISS] Redis cache miss (${l2Latency}ms)`)

    // ========================================================================
    // L3: Vertex AI Vector Search with Request Deduplication (100-3000ms)
    // ========================================================================
    console.log('[L3 Vertex AI] Cache miss - executing vector search...')

    // Use request deduplication to merge identical in-flight requests
    const results = await requestDeduplicator.execute(
      redisCacheKey,
      async () => {
        return await performVectorSearch(projectDescription, options)
      },
      { ttl: 10000 } // 10 second dedup window
    )

    const totalLatency = Date.now() - overallStartTime

    // Populate both cache layers
    await setInCache(redisCacheKey, results, CACHE_TTL.VECTOR_SEARCH)
    setInLocalCache(vectorSearchCache, 'vectorSearch', cacheKey, results)

    console.log(`[Vertex AI COMPLETE] ‚úÖ Returned ${results.length} results in ${totalLatency}ms`)

    return results
  } catch (error) {
    console.error('‚ùå [ERROR] Incident search failed:', error)
    throw new Error(
      'Failed to find similar incidents: ' + (error instanceof Error ? error.message : 'Unknown error')
    )
  }
}

/**
 * Load all incident data from Cloud Storage (cached)
 */
async function loadIncidentData(): Promise<Map<string, any[]>> {
  const now = Date.now()

  // Return cached data if still valid
  if (incidentCache && (now - cacheTimestamp) < CACHE_TTL_MS) {
    console.log('[Gemini Search] Using cached incident data')
    return incidentCache
  }

  console.log('[Gemini Search] Loading incident data from Cloud Storage...')

  const bucket = storage.bucket(BUCKET_NAME)
  const [files] = await bucket.getFiles({ prefix: INCIDENT_DATA_PATH })

  const jsonFiles = files.filter(file => file.name.endsWith('.json'))
  const dataMap = new Map<string, any[]>()

  for (const file of jsonFiles) {
    try {
      const tableName = file.name.split('/').pop()?.replace('.json', '') || 'unknown'
      const [content] = await file.download()
      const records = JSON.parse(content.toString()) as any[]

      dataMap.set(tableName, records)
      console.log(`[Gemini Search] Loaded ${records.length} records from ${tableName}`)
    } catch (error) {
      console.error(`[Gemini Search] Error loading ${file.name}:`, error)
    }
  }

  incidentCache = dataMap
  cacheTimestamp = now

  return dataMap
}

/**
 * Perform actual search using Gemini grounding
 * (separated for request deduplication)
 */
async function performVectorSearch(
  projectDescription: string,
  options: IncidentSearchOptions
): Promise<IncidentMatch[]> {
  const {
    limit = 20,
    minSimilarity = 0.7,
    industry,
    severity,
    requireMfaData = false,
    requireBackupData = false,
    requireIrPlanData = false,
    incidentTypes,
  } = options

  const searchStartTime = Date.now()

  console.log(`[Gemini Search] Searching for incidents...`)
  console.log(`[Gemini Search] Query: "${projectDescription.substring(0, 100)}..."`)

  // Step 1: Load all incident data from Cloud Storage
  const incidentData = await loadIncidentData()

  // Step 2: Flatten and pre-filter incidents
  interface IncidentRecord {
    id?: string | number
    [key: string]: any
  }

  let allIncidents: Array<IncidentRecord & { type: string }> = []

  for (const [type, records] of incidentData.entries()) {
    records.forEach(record => {
      // Pre-filter by industry
      if (industry && record.industry?.toLowerCase() !== industry.toLowerCase()) {
        return
      }

      // Pre-filter by severity
      if (severity && severity.length > 0) {
        if (!record.severity || !severity.includes(record.severity)) {
          return
        }
      }

      // Pre-filter by incident type
      const recordType = mapTableToIncidentType(type)
      if (incidentTypes && incidentTypes.length > 0) {
        if (!incidentTypes.includes(recordType)) {
          return
        }
      }

      // Pre-filter by security data requirements
      if (requireMfaData && record.had_mfa === undefined && record.hadMfa === undefined) return
      if (requireBackupData && record.had_backups === undefined && record.hadBackups === undefined) return
      if (requireIrPlanData && record.had_ir_plan === undefined && record.hadIrPlan === undefined) return

      allIncidents.push({ ...record, type })
    })
  }

  console.log(`[Gemini Search] Found ${allIncidents.length} incidents after pre-filtering`)

  if (allIncidents.length === 0) {
    return []
  }

  // Step 3: Use Gemini to rank incidents by relevance
  const rankedIncidents = await rankIncidentsByRelevance(
    allIncidents,
    projectDescription,
    limit * 2 // Get 2x for better selection
  )

  // Step 4: Convert to IncidentMatch format
  const matches: IncidentMatch[] = rankedIncidents.slice(0, limit).map((incident, idx) => {
    const incidentType = mapTableToIncidentType(incident.type)

    // Calculate pseudo-similarity score (0.7-1.0 based on ranking)
    const similarity = Math.max(minSimilarity, 1.0 - (idx * 0.02))

    return {
      id: `${incident.type}_${incident.id || idx}`,
      incidentId: String(incident.id || idx),
      incidentType,
      attackType: incident.attack_type || incident.attackType || null,
      organization: incident.organization || null,
      industry: incident.industry || null,
      severity: incident.severity || null,
      incidentDate: incident.incident_date || incident.incidentDate
        ? new Date(incident.incident_date || incident.incidentDate)
        : null,
      hadMfa: incident.had_mfa ?? incident.hadMfa ?? null,
      hadBackups: incident.had_backups ?? incident.hadBackups ?? null,
      hadIrPlan: incident.had_ir_plan ?? incident.hadIrPlan ?? null,
      estimatedCost: incident.estimated_cost || incident.estimatedCost || null,
      downtimeHours: incident.downtime_hours || incident.downtimeHours || null,
      recordsAffected: incident.records_affected || incident.recordsAffected || null,
      similarity,
      embeddingText: createIncidentSummary(incident, incident.type),
    }
  })

  const searchLatency = Date.now() - searchStartTime
  console.log(`[Gemini Search] ‚úÖ Returned ${matches.length} matches in ${searchLatency}ms`)

  if (matches.length > 0) {
    const minSim = matches[matches.length - 1].similarity.toFixed(3)
    const maxSim = matches[0].similarity.toFixed(3)
    console.log(`[Gemini Search] Similarity range: ${minSim} - ${maxSim}`)
  }

  return matches
}

/**
 * Map table name to incident type
 */
function mapTableToIncidentType(tableName: string): string {
  const mapping: Record<string, string> = {
    'cyber_incident_staging': 'cyber',
    'cloud_incident_staging': 'cloud',
    'failure_patterns': 'failure_pattern',
    'security_vulnerabilities': 'vulnerability',
    'regulation_violations': 'regulation_violation',
    'cep_signal_events': 'cep_signal',
    'cep_anomalies': 'cep_anomaly',
    'cep_pattern_templates': 'cep_pattern',
  }
  return mapping[tableName] || tableName
}

/**
 * Use Gemini to rank incidents by relevance
 */
async function rankIncidentsByRelevance(
  incidents: Array<any & { type: string }>,
  projectDescription: string,
  limit: number
): Promise<Array<any & { type: string }>> {
  try {
    const gemini = getGeminiClient()

    // Create concise summaries for Gemini to evaluate
    const incidentSummaries = incidents.slice(0, 100).map((inc, idx) => ({
      index: idx,
      summary: createIncidentSummary(inc, inc.type)
    }))

    const prompt = `You are analyzing security incidents to find the most relevant ones for this project:

Project Description: ${projectDescription}

Here are ${incidentSummaries.length} security incidents. Select the ${limit} most relevant incident indexes (by number) that would provide the most valuable lessons for this project's risk assessment.

Incidents:
${incidentSummaries.map(s => `${s.index}. ${s.summary}`).join('\n')}

Respond with ONLY a JSON array of the ${limit} most relevant incident indexes, like: [0, 5, 12, ...]`

    const result = await gemini.generateContent(prompt)
    const response = result.response.candidates?.[0]?.content?.parts?.[0]?.text || ''

    // Parse the response to get selected indexes
    const match = response.match(/\[([\\d,\s]+)\]/)
    if (match) {
      const selectedIndexes = match[1].split(',').map((s: string) => parseInt(s.trim())).filter((n: number) => !isNaN(n))
      console.log(`[Gemini Search] Gemini selected indexes: ${selectedIndexes.slice(0, 10).join(', ')}${selectedIndexes.length > 10 ? '...' : ''}`)

      const selected = selectedIndexes
        .filter((idx: number) => idx < incidents.length)
        .map((idx: number) => incidents[idx])

      return selected.slice(0, limit)
    }
  } catch (error) {
    console.error('[Gemini Search] Error using Gemini for ranking:', error)
  }

  // Fallback: return first N incidents
  console.log('[Gemini Search] Using fallback: returning first incidents')
  return incidents.slice(0, limit)
}

/**
 * Create a concise summary of an incident for Gemini evaluation
 */
function createIncidentSummary(incident: any, type: string): string {
  if (type === 'cyber_incident_staging') {
    return `${incident.attack_type || 'Unknown attack'} on ${incident.organization || 'Unknown org'} (${incident.industry || 'Unknown industry'}) - ${incident.severity || 'unknown'} severity, $${incident.estimated_cost || 'unknown'} cost`
  }

  if (type === 'cloud_incident_staging') {
    return `${incident.cloud_provider || 'Cloud'} ${incident.affected_service || 'service'} - ${incident.incident_type || 'incident'} affecting ${incident.affected_customers || 'unknown'} customers`
  }

  if (type === 'failure_patterns') {
    return `${incident.pattern_type || 'Unknown'} failure in ${incident.category || 'unknown'} - occurs ${incident.occurrence_frequency || 'unknown frequency'}`
  }

  if (type === 'security_vulnerabilities') {
    return `${incident.cve_id || 'Unknown CVE'}: ${incident.vulnerability_type || 'vulnerability'} (CVSS ${incident.cvss_score || 'N/A'}) in ${incident.affected_products?.join(', ') || 'unknown products'}`
  }

  if (type === 'regulation_violations') {
    return `${incident.regulation_framework || 'Regulation'} violation by ${incident.organization || 'unknown'} - ${incident.violation_type || 'violation'}, fine: $${incident.fine_amount || 'unknown'}`
  }

  if (type === 'cep_signal_events') {
    return `CEP Signal: ${incident.event_type || 'event'} from ${incident.source || 'unknown'} - ${incident.severity || 'unknown'} severity`
  }

  return `${type}: ${incident.description || incident.title || JSON.stringify(incident).slice(0, 100)}...`
}

/**
 * Calculate statistics from a set of incident matches
 */
export function calculateIncidentStatistics(incidents: IncidentMatch[]): IncidentStatistics {
  console.log('\nüìä Calculating statistics for ' + incidents.length + ' incidents...')

  if (incidents.length === 0) {
    console.log('No incidents to analyze')
    return {
      totalIncidents: 0,
      dateRange: {},
      avgCost: 0,
      medianCost: 0,
      totalCost: 0,
      incidentsWithCostData: 0,
      avgDowntime: 0,
      totalDowntime: 0,
      incidentsWithDowntimeData: 0,
      avgRecordsAffected: 0,
      totalRecordsAffected: 0,
      incidentsWithRecordsData: 0,
      mfaAdoptionRate: 0,
      backupAdoptionRate: 0,
      irPlanAdoptionRate: 0,
      incidentsWithSecurityData: 0,
      costSavingsMfa: 0,
      costSavingsBackups: 0,
      costSavingsIrPlan: 0,
      avgCostWithMfa: 0,
      avgCostWithoutMfa: 0,
      avgCostWithBackups: 0,
      avgCostWithoutBackups: 0,
      avgCostWithIrPlan: 0,
      avgCostWithoutIrPlan: 0,
      severityBreakdown: { low: 0, medium: 0, high: 0, critical: 0, unknown: 0 },
      topIndustries: [],
    }
  }

  const toNumber = (val: bigint | number | null | undefined): number => {
    if (val === null || val === undefined) return 0
    return typeof val === 'bigint' ? Number(val) : val
  }

  // Date range analysis
  const dates = incidents.map((i) => i.incidentDate).filter((d): d is Date => d !== null && d !== undefined)
  const dateRange = {
    earliest: dates.length > 0 ? new Date(Math.min(...dates.map((d) => d.getTime()))) : undefined,
    latest: dates.length > 0 ? new Date(Math.max(...dates.map((d) => d.getTime()))) : undefined,
  }

  // Cost statistics
  const costsData = incidents.map((i) => toNumber(i.estimatedCost)).filter((c) => c > 0)
  const totalCost = costsData.reduce((sum, c) => sum + c, 0)
  const avgCost = costsData.length > 0 ? totalCost / costsData.length : 0
  const sortedCosts = [...costsData].sort((a, b) => a - b)
  const medianCost = costsData.length > 0 ? sortedCosts[Math.floor(costsData.length / 2)] : 0

  // Downtime statistics
  const downtimeData = incidents.map((i) => i.downtimeHours).filter((d): d is number => d !== null && d !== undefined && d > 0)
  const totalDowntime = downtimeData.reduce((sum, d) => sum + d, 0)
  const avgDowntime = downtimeData.length > 0 ? totalDowntime / downtimeData.length : 0

  // Records affected statistics
  const recordsData = incidents.map((i) => i.recordsAffected).filter((r): r is number => r !== null && r !== undefined && r > 0)
  const totalRecordsAffected = recordsData.reduce((sum, r) => sum + r, 0)
  const avgRecordsAffected = recordsData.length > 0 ? totalRecordsAffected / recordsData.length : 0

  // Security control adoption rates
  const withSecurityData = incidents.filter((i) => i.hadMfa !== null || i.hadBackups !== null || i.hadIrPlan !== null)
  const incidentsWithSecurityData = withSecurityData.length

  const mfaData = incidents.filter((i) => i.hadMfa !== null)
  const mfaTrue = mfaData.filter((i) => i.hadMfa === true)
  const mfaAdoptionRate = mfaData.length > 0 ? (mfaTrue.length / mfaData.length) * 100 : 0

  const backupData = incidents.filter((i) => i.hadBackups !== null)
  const backupTrue = backupData.filter((i) => i.hadBackups === true)
  const backupAdoptionRate = backupData.length > 0 ? (backupTrue.length / backupData.length) * 100 : 0

  const irPlanData = incidents.filter((i) => i.hadIrPlan !== null)
  const irPlanTrue = irPlanData.filter((i) => i.hadIrPlan === true)
  const irPlanAdoptionRate = irPlanData.length > 0 ? (irPlanTrue.length / irPlanData.length) * 100 : 0

  // Cost savings analysis (with vs without security controls)
  const incidentsWithMfa = incidents.filter((i) => i.hadMfa === true && i.estimatedCost && toNumber(i.estimatedCost) > 0)
  const incidentsWithoutMfa = incidents.filter((i) => i.hadMfa === false && i.estimatedCost && toNumber(i.estimatedCost) > 0)
  const avgCostWithMfa = incidentsWithMfa.length > 0 ? incidentsWithMfa.reduce((sum, i) => sum + toNumber(i.estimatedCost), 0) / incidentsWithMfa.length : 0
  const avgCostWithoutMfa = incidentsWithoutMfa.length > 0 ? incidentsWithoutMfa.reduce((sum, i) => sum + toNumber(i.estimatedCost), 0) / incidentsWithoutMfa.length : 0
  const costSavingsMfa = avgCostWithoutMfa - avgCostWithMfa

  const incidentsWithBackups = incidents.filter((i) => i.hadBackups === true && i.estimatedCost && toNumber(i.estimatedCost) > 0)
  const incidentsWithoutBackups = incidents.filter((i) => i.hadBackups === false && i.estimatedCost && toNumber(i.estimatedCost) > 0)
  const avgCostWithBackups = incidentsWithBackups.length > 0 ? incidentsWithBackups.reduce((sum, i) => sum + toNumber(i.estimatedCost), 0) / incidentsWithBackups.length : 0
  const avgCostWithoutBackups = incidentsWithoutBackups.length > 0 ? incidentsWithoutBackups.reduce((sum, i) => sum + toNumber(i.estimatedCost), 0) / incidentsWithoutBackups.length : 0
  const costSavingsBackups = avgCostWithoutBackups - avgCostWithBackups

  const incidentsWithIrPlan = incidents.filter((i) => i.hadIrPlan === true && i.estimatedCost && toNumber(i.estimatedCost) > 0)
  const incidentsWithoutIrPlan = incidents.filter((i) => i.hadIrPlan === false && i.estimatedCost && toNumber(i.estimatedCost) > 0)
  const avgCostWithIrPlan = incidentsWithIrPlan.length > 0 ? incidentsWithIrPlan.reduce((sum, i) => sum + toNumber(i.estimatedCost), 0) / incidentsWithIrPlan.length : 0
  const avgCostWithoutIrPlan = incidentsWithoutIrPlan.length > 0 ? incidentsWithoutIrPlan.reduce((sum, i) => sum + toNumber(i.estimatedCost), 0) / incidentsWithoutIrPlan.length : 0
  const costSavingsIrPlan = avgCostWithoutIrPlan - avgCostWithIrPlan

  // Severity breakdown
  const severityBreakdown = {
    low: incidents.filter((i) => i.severity?.toLowerCase() === 'low').length,
    medium: incidents.filter((i) => i.severity?.toLowerCase() === 'medium').length,
    high: incidents.filter((i) => i.severity?.toLowerCase() === 'high').length,
    critical: incidents.filter((i) => i.severity?.toLowerCase() === 'critical').length,
    unknown: incidents.filter((i) => !i.severity).length,
  }

  // Top industries
  const industryCount = new Map<string, number>()
  incidents.forEach((i) => {
    if (i.industry) {
      const count = industryCount.get(i.industry) || 0
      industryCount.set(i.industry, count + 1)
    }
  })
  const topIndustries = Array.from(industryCount.entries())
    .map(([industry, count]) => ({ industry, count }))
    .sort((a, b) => b.count - a.count)
    .slice(0, 5)

  const stats: IncidentStatistics = {
    totalIncidents: incidents.length,
    dateRange,
    avgCost,
    medianCost,
    totalCost,
    incidentsWithCostData: costsData.length,
    avgDowntime,
    totalDowntime,
    incidentsWithDowntimeData: downtimeData.length,
    avgRecordsAffected,
    totalRecordsAffected,
    incidentsWithRecordsData: recordsData.length,
    mfaAdoptionRate,
    backupAdoptionRate,
    irPlanAdoptionRate,
    incidentsWithSecurityData,
    costSavingsMfa,
    costSavingsBackups,
    costSavingsIrPlan,
    avgCostWithMfa,
    avgCostWithoutMfa,
    avgCostWithBackups,
    avgCostWithoutBackups,
    avgCostWithIrPlan,
    avgCostWithoutIrPlan,
    severityBreakdown,
    topIndustries,
  }

  console.log('  ' + stats.totalIncidents + ' total incidents analyzed')
  console.log('  ' + stats.incidentsWithCostData + ' incidents with cost data (avg: $' + stats.avgCost.toLocaleString() + ')')
  console.log('  ' + stats.incidentsWithSecurityData + ' incidents with security control data')
  console.log('  MFA adoption: ' + stats.mfaAdoptionRate.toFixed(1) + '%')
  console.log('  Backup adoption: ' + stats.backupAdoptionRate.toFixed(1) + '%')
  console.log('  IR Plan adoption: ' + stats.irPlanAdoptionRate.toFixed(1) + '%')

  if (costSavingsMfa > 0) {
    console.log('  üí∞ MFA cost savings: $' + costSavingsMfa.toLocaleString() + ' (' + incidentsWithMfa.length + ' with vs ' + incidentsWithoutMfa.length + ' without)')
  }
  if (costSavingsBackups > 0) {
    console.log('  üí∞ Backup cost savings: $' + costSavingsBackups.toLocaleString() + ' (' + incidentsWithBackups.length + ' with vs ' + incidentsWithoutBackups.length + ' without)')
  }
  if (costSavingsIrPlan > 0) {
    console.log('  üí∞ IR Plan cost savings: $' + costSavingsIrPlan.toLocaleString() + ' (' + incidentsWithIrPlan.length + ' with vs ' + incidentsWithoutIrPlan.length + ' without)')
  }

  return stats
}
